## 1.2.1 Linear Recursion and Iteration

We begin by considering the factorial function, defined by

`n! = n * (n-1) * (n-2) *** 3 * 2 * 2`

There are many ways to compute factorials. One way is to make use of the observation that `n!` is equal to `n` times `(n-1)!` for any positiveinteger `n`:

`n! = n * [(n-1) * (n-2) ... * 3 * 2 * 1] = n * (n-1)!`

Thus, we can compute `n!` by computing `(n-1)!` and multiplying the result by `n`. If we add the stipulation of that `1!` is egual to `1`, this observation translates directly into a procedure:

```Lisp
(define (factorial n)
 (if (= n 1)
    1
 (* n (factorial (- n 1)))))
 ```

 ```Lisp
(factorial 7) ------------------------------------------
(* 7 (factorial 6))                                    |
(* 7 (* 6 (factorial 5)))                              |
(* 7 (* 6 (* 5 (factorial 4))))                        |
(* 7 (* 6 (* 5 (* 4 (factorial 3)))))                  |
(* 7 (* 6 (* 5 (* 4 (* 3 (factorial 2))))))            |
(* 7 (* 6 (* 5 (* 4 (* 3 (* 2 (factorial 1)))))))      |
(* 7 (* 6 (* 5 (* 4 (* 3 (* 2 1))))))                  |
(* 7 (* 6 (* 5 (* 4 (* 3 2)))))                        |
(* 7 (* 6 (* 5 (* 4 6))))                              |
(* 7 (* 6 (* 5 24)))                                   |
(* 7 (* 6 120))                                        |
(* 7 720)                                              |
5040    <-----------------------------------------------            
 ```
**Figure 1.3:** A linear recursion process for computing 7!

 We can use the subsitution model of  [Section 1.1.5](1.1.5_the_substitution_model_for_proceducre_application.md) to watch this procedure in action computing `6!`, as shown in Figure 1.3.

 Now let's take a different perspecitve on comuting factorials. We could describe a rule for computing `n!` by specifying that we first multiply 1 by 2, than multiply the result by 3, than by 4, ans so on untill we reach `n`. More formally, we maintain a running product, together with a counter that count from 1 up to `n`. We can describe the computation by saying that the counter and the product simultaneously change from one step to the next according to the rule

 ```
 product <= counter * product
 counter <= counter + 1
 ```

 and stipulating than `n!` is the value of the product when the counter exceeds `n`.

 Once again, we can recast our description as a procdure for computing factorials: *(29)*

 > *(29)* In a real program we would probably use the block structure introduced in the last section to hide the definition of `fact-iter`:

 ```Lisp
 (define (factorial n)
    (define (iter product counter)
        (if (> counter n)
            product
            (iter (* counter product)
            (+ counter 1))))
 (iter 1 1))
 ```
 > We avoided doing this here so as to minimize the number of thing to think about a once.

 ```Lisp
(factorial 7) -----------
(fact-iter 1 1 7)       |
(fact-iter 1 2 7)       |
(fact-iter 2 3 7)       |
(fact-iter 6 4 7)       |
(fact-iter 24 5 7)      |
(fact-iter 120 6 7)     |
(fact-iter 720 7 7)     |
(fact-iter 5040 8 7)    |    
5040 <------------------|
 ```

 **Figrue 1.4:** A linear iterative process for computing 7!.


 ```Lisp
 (define (factorial n) 
    (fact-iter 1 1 n))
(define (fact-iter product counter max-count)
(if (> counter max-count)
    product
    (fact-iter (* counter product)
            (+ counter 1)
        max-count)))
 ```

 As befro, we can use the substutution model to visualize the process of computing `6!`, as show in Figure 1.4.

 Compare the two processes. From one point of view, they seem hardly different at all. Both compute the same mathematical function on the same domain, and each requires a number of steps proportional to `n` to compute `n!`. Indeed, both processes even carry out the same sequence of multiplications, obtaining the same sequecnd of patial products. On the other hand, when we consider the "shapes" of the two processes, we find that than evolve quite differntly.

Consider the first process. The substitution model reveals a shape of expansion followed by contraction, indicated by arrow in **Figure 1.3**. The expansion occurs as the process builds up a chain of *deferred operations* (in this case, a chain of multiplications). The contraction occurs as the operations are actually performed. This type of process, charatrized by a chain of deffered operations, is called a *recursive process*. Carrion out this process requires that the interpreter keep thack of the operation to be performed later on. In the computation of `n!`, the length of the chain of deffered multiplicaion, and hence the amount of information needed to keep track of it, grows lineary with `n` (is proportional to `n`), just like the number of steps. Such a process is called a *linear recursive process*.

By contrast, the second process does not grow and shrink. At each step, all we need to keep track of, for any `n`, are thre current values of the variables `product`, `counter`, and `max-count`. We call this an `iterative process`. In general, an iterative process is one whose state can be summarized by a fixed number of `state variables`, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an (optional) end test aht secifies conditions under which the process should termintate. In computing `n!`, the number of steps requried grows lineary with `n`. Such a proces is called `linear iterative process`.

The constrast between the two processes can be seen in another way. In the iterative case, the programm variables provide a complete description of the state of the process at any point. If we stopped the computation between steps, all we would need to do to resume the computation is to supply the interpreter with the value of the three program variables. Not so with the recuresive porcess. In this case there is some additional "hidden" information, maintained by the interpreter and not contained in the program variables, which indecates "where the process is" in negotiating the chain of deferred operations. The Longer the chain, the more infromation must be maintained. *(30)*

> *(30)* When we discuss the implementation of procedures on register machines in Chapter 5, we will see that any iterative process cn be realized "in hardware" as a machine that has a fixes set of register and no auxiliary memory. In contrast, realizing a recursime process requires a machine that uses an auxiliary data structure known as a `stack`

In contrasting iteration and recursion, we must be careful not to confuse the notion of a recursive *process* with the notion of a recursive *pocedure*. When we describe a procedure as recursive, we are referring the syntactic fact that the procedure definition refers (either directli or indirectly) to the procedure itself. But when we describe a process as following a pattern that is, say, linearly recursive, we are speaking about how the rpcess evolves, not about the syntax of how a procedure is written. It may seem disturbing that we refer to a recursive procedure such as `fact-iter` as generating an iterative process. However, the process really is iterative: It's state is captured completely by its three state varoab;es, and an interpreter need keep track only three variables in order to execuÐµe the pocess.

One reason that the sistinction between process and procedure may be confusing is that most implementation of common languages (including Ada, Pascal, and C) are designed in such a way that interpretation of any recursive procedure consumes an amount of memory that grows with the number of procedure calls, even when the process described is, in priciple, iterative. As a consequecne, these languages can describe iterative processes only by resorting to speial-purpose "looping constucts" sach as `do`, `repeat`, `until`, `for` and `while`. The implementation of Scheme we shall consider in **Chapter 5** does not shar this defect. It will execute and interative process in constan space, even if the iterative process is described by a recursive procedure. An implementation with this property is called *tail_recusive*. With a tail-recursive implementation, iteration can be expressed using the ordinary procedure call mechanism, so that secisl iteration construcs are useful only as syntatctic sugar. *(31)*

> *(31)* Tail recursion has long been known as a compiler optimisatin trick. A coherent semantic basis for tail recursion was provided by Carl Hewitt (1977), who exmpained it in terms of the "message-passing" model of computation that we shall discuss in Chapter 3. Inspired by this, Gerald Jas Sussman and Guy Lewis Stelle Jr. (see Steele and Sussman 1975) constructed a tail-recursive interpreter for Scheme. Steele later showed how tail recursion is a consequence of the natural way to compile procedure calls (Steele 1977). The IEEE stadard for Scheme requires the Scheme implementation be tail-recursive.



### Exersice 1.9:

Each of the following two procedures defines a method for adding two positive integers in term of the procedures `inc`, wich increments it's argument by 1, and `dec` which decrements its argument by 1.

```Lisp
(define (+ a b)
    (if (= a 0) 
        b 
        (inc (+ (dec a) b))))
```


```Lisp
(+ 4 5)
(inc (+ 3 5))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9
```

```Lisp
(define (+ a b)
    (if (= a 0)
        b
        (+ (dec a) (inc b))))
```

```Lisp
(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9
```

Using the substitution model, illustrate the porcess generated by each procedure in evaluation `(+ 4 5)`. Are these processes iterative or recursive?

**Answer**: First process is recursive one, and seciond is iterative.

### Exercise 1.10:

The following procedure computes a mathematical function called Ackermann's function.

```Lisp
(define (A x y)
    (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (-  x 1) (A x (- y 1))))
    ))
```

What are the values of the following expressions?

```Lisp
(A 1 10)
(A 2 4)
(A 3 3)
```

Consider the following procedures, where `A` is the procedure defined above:

```Lisp
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
```

Give concise mathematical definitions for the functions computed by the procedures `f`,`g`, and `h` for positive integer values of `n`. For example, `(k n)` computes `5*n*n`.

### Solutions:

Functions | A notation | Mathemstical definitions
--- | --- | --- 
(f n) | (A 0 n) | 2 * n
(g n) | (A 1 n) | 2**n
(h n) | (A 2 n) | 2**(2**(2**(...))) n-1 times: (A 2 4) => `2**(2**(2**2))`
(k n) | ( ) |  5 * n ** 2


```Lisp
(A 1 10)
(A (- 1 1) (A 1 (- 10 1)))
(A 0 (A 1 9))
(A 0 (A (-1 1) A(1 (- 9 1))))
(A 0 (A 0 (A 1 8)))
(A 0 (A 0 (A 0 (A 1 (- 8 1)))))
(A 0 (A 0 (A 0 (A 1 7))))
(A 0 (A 0 (A 0 (A 0 (A 1 (- 7 1))))))
(A 0 (A 0 (A 0 (A 0 (A 1 6)))))
(A 0 (A 0 (A 0 (A 0 (A 0 A( 1 (- 6 1)))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 1 5))))))
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 1 4)))))))
;. . .
; (n - x) (x)
(A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 0 (A 1 1))))))))))
(* 2 (* 2 (* 2 (* 2 (* 2 (* 2 (* 2 (* 2 (* 2 2)))))))))
```

(A 1 10) == 2^10
(A 1 n) == 2**n

```Lisp
(A 1 3)
(A 0 (A 1 2))
(A 0 (A 0 (A 1 1)))
(A 0 (A 0 2))
(* 2 (* 2 2))
; (A 1 3) == 2**3 
```

## (A 2 4)

```Lisp
(A 2 4) ; call
(A 1 (A 2 3)) ; call
(A 1 (A 1 (A 2 2)))
(A 1 (A 1 (A 1 (A 2 1))))
(A 1 (A 1 (A 1 2))) ; call
(A 1 (A 1 (A 0 (A 1 1))))
(A 1 (A 1 (A 0 2)))
(A 1 (A 1 4))
(A 1 (A 0 (A 1 3)))
(A 1 (A 0 8))
(A 1 16)
(A 0 (A 1 15))
(A 0 2^^15)
2**16
2**(2**4)
2**(2**(2**2))

``` 


```Lisp
; (A 2 0)
(A 2 0)
0
;;;;;;;;;;;;;;;;;;;;;;;;
;(A 2 1)
(A 2 1)
2
;;;;;;;;;
;(A 2 2)
(A 2 2)
(A 1 (A 2 1))
(A 1 2)
2**(2)

;;;;;
;(A 2 3)
(A 2 3)
(A 1 (A 2 2))
(A 1 4)
2**(2**2)

;;;;;
;(A 2 4)
(A 2 4)
(A 1 (A 2 3))
(A 1 2**4)
2**(2**(2**2))
```
**65536** Correct: http://community.schemewiki.org/?sicp-ex-1.10

#### (A 3 3)

```Lisp
;;;;;
;; (A 3 3)
(A 3 3)
(A 2 (A 3 2))
(A 2 (A 2 (A 3 1)))
(A 2 (A 2 2))
(A 2 4)
2**(2**(2**2))
```
**65536** Correct: http://community.schemewiki.org/?sicp-ex-1.10


